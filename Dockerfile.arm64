FROM --platform=linux/arm64 debian:bookworm-slim AS builder

RUN apt-get update && \
    apt-get install -y curl git python3 python3-pip python3-venv build-essential && \
    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/* && \
    mkdir -p /Whisper-WebUI

WORKDIR /Whisper-WebUI

# Copy requirements first for better layer caching
COPY requirements.txt .

# Copy project files (including potential local git dependencies in subdirectories)
# This allows using local git repos if they exist, otherwise will use remote
COPY . .

# Install PyTorch for ARM64 with GPU support (for NVIDIA Jetson)
# For NVIDIA Jetson devices, use PyTorch from NVIDIA's repository
# For other ARM devices, this will fall back to CPU version
# Try to use local git dependencies if available in project root, otherwise use remote
RUN python3 -m venv venv && \
    . venv/bin/activate && \
    pip install --upgrade pip setuptools wheel

# Install PyTorch with ARM64 GPU support
# For NVIDIA DGX ARM systems, try multiple methods to get CUDA-enabled PyTorch
RUN . venv/bin/activate && \
    echo "Attempting to install PyTorch CUDA version for ARM64..." && \
    echo "Method 1: Try PyTorch official CUDA repository..." && \
    (pip install "torch>=2.8.0,<2.9.0" "torchaudio>=2.8.0,<2.9.0" --index-url https://download.pytorch.org/whl/cu128 2>&1 | tee /tmp/pytorch_install.log && \
     python -c "import torch; cuda_ok = torch.cuda.is_available(); print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {cuda_ok}'); print(f'CUDA version: {torch.version.cuda if cuda_ok else \"N/A\"}'); exit(0 if cuda_ok else 1)" && \
     echo "SUCCESS: PyTorch CUDA version installed from official repo!") || \
    (echo "Method 1 failed, trying Method 2: Install without version constraint..." && \
     pip uninstall -y torch torchaudio 2>/dev/null || true && \
     pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu128 2>&1 | tee /tmp/pytorch_install2.log && \
     python -c "import torch; cuda_ok = torch.cuda.is_available(); print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {cuda_ok}'); print(f'CUDA version: {torch.version.cuda if cuda_ok else \"N/A\"}'); exit(0 if cuda_ok else 1)" && \
     echo "SUCCESS: PyTorch CUDA version installed (without version constraint)!") || \
    (echo "Method 2 failed, trying Method 3: Try CUDA 12.1..." && \
     pip uninstall -y torch torchaudio 2>/dev/null || true && \
     pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121 2>&1 | tee /tmp/pytorch_install3.log && \
     python -c "import torch; cuda_ok = torch.cuda.is_available(); print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {cuda_ok}'); print(f'CUDA version: {torch.version.cuda if cuda_ok else \"N/A\"}'); exit(0 if cuda_ok else 1)" && \
     echo "SUCCESS: PyTorch CUDA version installed (CUDA 12.1)!") || \
    (echo "All CUDA methods failed. Installing CPU version as fallback..." && \
     echo "NOTE: For NVIDIA DGX ARM systems, GPU support may require:" && \
     echo "  1. Using NVIDIA PyTorch container as base image" && \
     echo "  2. Building PyTorch from source with CUDA support" && \
     echo "  3. Using pre-built PyTorch from NVIDIA's repository" && \
     pip uninstall -y torch torchaudio 2>/dev/null || true && \
     pip install "torch>=2.8.0,<2.9.0" "torchaudio>=2.8.0,<2.9.0" --index-url https://download.pytorch.org/whl/cpu && \
     python -c "import torch; print(f'PyTorch CPU version: {torch.__version__}'); print('WARNING: CPU version installed - GPU will not be available at build time!')" && \
     echo "GPU support will be checked at runtime")

# Install other Python packages
RUN . venv/bin/activate && \
    pip install matplotlib faster-whisper==1.1.1 transformers==4.47.1 gradio==5.29.0 gradio-i18n==0.3.1 pytubefix ruamel.yaml==0.18.6 pyannote.audio==3.3.2

# Install git dependencies - try local first, fallback to remote
# Note: Using relative paths since WORKDIR is already /Whisper-WebUI
# Install older setuptools version that includes pkg_resources, then use pip install (not -e) for proper installation
RUN /Whisper-WebUI/venv/bin/pip install "setuptools<70" && \
    /Whisper-WebUI/venv/bin/python -c "import pkg_resources; print('pkg_resources available')" && \
    if [ -d "jhj0517-whisper" ] && [ -f "jhj0517-whisper/setup.py" ]; then \
        echo "Using local jhj0517-whisper"; \
        /Whisper-WebUI/venv/bin/pip install --no-build-isolation ./jhj0517-whisper && \
        /Whisper-WebUI/venv/bin/python -c "import whisper; print('whisper module installed successfully')"; \
    else \
        echo "Installing jhj0517-whisper from GitHub"; \
        cd /tmp && \
        git clone --depth 1 https://github.com/jhj0517/jhj0517-whisper.git && \
        /Whisper-WebUI/venv/bin/pip install --no-build-isolation /tmp/jhj0517-whisper && \
        /Whisper-WebUI/venv/bin/python -c "import whisper; print('whisper module installed successfully')" && \
        cd /Whisper-WebUI && \
        rm -rf /tmp/jhj0517-whisper; \
    fi

RUN if [ -d "ultimatevocalremover_api" ] && [ -f "ultimatevocalremover_api/setup.py" ]; then \
        echo "Using local ultimatevocalremover_api"; \
        /Whisper-WebUI/venv/bin/pip install --no-build-isolation --no-deps ./ultimatevocalremover_api; \
    else \
        echo "Installing ultimatevocalremover_api from GitHub"; \
        cd /tmp && \
        git clone --depth 1 https://github.com/jhj0517/ultimatevocalremover_api.git && \
        /Whisper-WebUI/venv/bin/pip install --no-build-isolation --no-deps /tmp/ultimatevocalremover_api && \
        cd /Whisper-WebUI && \
        rm -rf /tmp/ultimatevocalremover_api; \
    fi

# Install missing dependencies for uvr module
RUN /Whisper-WebUI/venv/bin/pip install openunmix && \
    /Whisper-WebUI/venv/bin/python -c "import uvr; print('uvr module installed successfully')"

RUN if [ -d "pyrubberband" ] && [ -f "pyrubberband/setup.py" ]; then \
        echo "Using local pyrubberband"; \
        cd pyrubberband && \
        /Whisper-WebUI/venv/bin/python setup.py develop && \
        cd ..; \
    else \
        echo "Installing pyrubberband from GitHub"; \
        cd /tmp && \
        git clone --depth 1 https://github.com/jhj0517/pyrubberband.git && \
        cd pyrubberband && \
        /Whisper-WebUI/venv/bin/python setup.py develop && \
        cd /Whisper-WebUI && \
        rm -rf /tmp/pyrubberband; \
    fi


FROM --platform=linux/arm64 debian:bookworm-slim AS runtime

# Install NVIDIA utilities for GPU access
# Note: For NVIDIA DGX/ARM systems, nvidia-smi should be available via NVIDIA Container Runtime
# But we install nvidia-utils as fallback
RUN apt-get update && \
    apt-get install -y curl ffmpeg python3 gnupg2 wget && \
    (wget -qO - https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/arm64/3bf863cc.pub | apt-key add - || true) && \
    (apt-get install -y nvidia-utils || echo "nvidia-utils not available in repo, will use host drivers") && \
    rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*

WORKDIR /Whisper-WebUI

# Copy project files first
COPY . .
# Then copy venv from builder (this will preserve the venv)
COPY --from=builder /Whisper-WebUI/venv /Whisper-WebUI/venv
# Verify modules are available in runtime
RUN /Whisper-WebUI/venv/bin/python -c "import whisper; print('whisper module verified')" && \
    (/Whisper-WebUI/venv/bin/python -c "import uvr; print('uvr module verified')" || \
     (echo "Warning: uvr module not found, attempting to reinstall..." && \
      cd /tmp && \
      git clone --depth 1 https://github.com/jhj0517/ultimatevocalremover_api.git && \
      /Whisper-WebUI/venv/bin/pip install --no-build-isolation --no-deps /tmp/ultimatevocalremover_api && \
      /Whisper-WebUI/venv/bin/pip install openunmix && \
      rm -rf /tmp/ultimatevocalremover_api && \
      /Whisper-WebUI/venv/bin/python -c "import uvr; print('uvr module reinstalled successfully')"))
RUN mkdir -p /Whisper-WebUI/configs_default && \
    cp -a /Whisper-WebUI/configs/. /Whisper-WebUI/configs_default/

VOLUME [ "/Whisper-WebUI/models" ]
VOLUME [ "/Whisper-WebUI/outputs" ]

ENV PATH="/Whisper-WebUI/venv/bin:$PATH"
# Set LD_LIBRARY_PATH to include CUDA libraries from host and PyTorch
ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/lib/aarch64-linux-gnu:/Whisper-WebUI/venv/lib64/python3.11/site-packages/nvidia/cublas/lib:/Whisper-WebUI/venv/lib64/python3.11/site-packages/nvidia/cudnn/lib:${LD_LIBRARY_PATH}

# Copy GPU check script
COPY check_gpu.py /Whisper-WebUI/check_gpu.py

# Create entrypoint script that checks GPU and attempts to use CUDA version if available
RUN echo '#!/bin/sh\n\
echo "Checking GPU availability..."\n\
python /Whisper-WebUI/check_gpu.py\n\
echo "Starting application..."\n\
exec python /Whisper-WebUI/app.py "$@"' > /Whisper-WebUI/entrypoint.sh && \
    chmod +x /Whisper-WebUI/entrypoint.sh

ENTRYPOINT [ "/Whisper-WebUI/entrypoint.sh" ]

