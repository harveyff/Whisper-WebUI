services:
  whisper-webui:
    container_name: whisper-webui
    build:
      context: .
      dockerfile: Dockerfile.arm64
    image: jhj0517/whisper-webui:arm64

    volumes:
      # You can mount the container's volume paths to directory paths on your local machine.
      # Models will be stored in the `./models' directory on your machine.
      # Similarly, all output files will be stored in the `./outputs` directory.
      - ./models:/Whisper-WebUI/models
      - ./outputs:/Whisper-WebUI/outputs
      - ./configs:/Whisper-WebUI/configs

    ports:
      - "7860:7860"

    stdin_open: true
    tty: true

    entrypoint: ["python", "app.py", "--server_port", "7860", "--server_name", "0.0.0.0",]

    # GPU support for ARM64 (NVIDIA DGX/Jetson devices)
    # Ensure NVIDIA Container Runtime is installed on host
    # For NVIDIA DGX systems, GPU access is provided via NVIDIA Container Runtime
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    
    # Alternative: Use runtime instead of deploy (for older docker-compose versions)
    # runtime: nvidia

